# ë©€í‹°ëª¨ë‹¬ ê°ì²´ íƒì§€ ëª¨ë¸ í›ˆë ¨ ë°©ë²•ë¡ 

**ëª©í‘œ**: ì—´ìƒ + ì•¼ê°„íˆ¬ì‹œ + Enhanced ê°€ì‹œê´‘ 3-way ì…ë ¥ì„ í™œìš©í•œ ì•¼ê°„ Person íƒì§€

---

## 1. ë©€í‹°ëª¨ë‹¬ ìœµí•© ì•„í‚¤í…ì²˜ ë°©ì•ˆ

### ë°©ì•ˆ 1: Early Fusion (ì´ˆê¸° ìœµí•©)
```
[ì—´ìƒ] â”€â”€â”
[ì•¼ê°„íˆ¬ì‹œ] â”€â”¼â”€> Concat/Stack â”€> Single Backbone â”€> Detection Head â”€> Output
[ê°€ì‹œê´‘] â”€â”€â”˜
```

**êµ¬í˜„**:
- 3ê°œ ì´ë¯¸ì§€ë¥¼ ì±„ë„ ì¶•ìœ¼ë¡œ ì—°ê²° (3+3+3 = 9ì±„ë„ ë˜ëŠ” 1+1+3 = 5ì±„ë„)
- YOLO ë°±ë³¸ì˜ ì²« Conv ë ˆì´ì–´ë¥¼ 9ì±„ë„ ì…ë ¥ìœ¼ë¡œ ìˆ˜ì •
- ë‹¨ì¼ ë„¤íŠ¸ì›Œí¬ê°€ ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ ë™ì‹œì— í•™ìŠµ

**ì¥ì **:
- êµ¬í˜„ ê°„ë‹¨, ê¸°ì¡´ YOLO êµ¬ì¡° ê±°ì˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- ëª¨ë‹¬ë¦¬í‹° ê°„ ì €ìˆ˜ì¤€(low-level) íŠ¹ì§• ìœµí•© ê°€ëŠ¥
- ì¶”ë¡  ì†ë„ ë¹ ë¦„

**ë‹¨ì **:
- ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ë…ë¦½ì  íŠ¹ì§• ì¶”ì¶œ ëŠ¥ë ¥ ì œí•œ
- í•œ ëª¨ë‹¬ë¦¬í‹°ê°€ í’ˆì§ˆ ë‚®ìœ¼ë©´ ì „ì²´ ì„±ëŠ¥ ì €í•˜
- ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ í™œìš© ì–´ë ¤ì›€ (ì…ë ¥ ì±„ë„ ìˆ˜ ë³€ê²½)

**ì½”ë“œ ì˜ˆì‹œ (YOLOv8/v11 ê¸°ë°˜)**:
```python
# ì…ë ¥ ì±„ë„ ìˆ˜ì •
model = YOLO('yolo11x.pt')
# Conv2d(3 -> 9) ì²« ë ˆì´ì–´ ìˆ˜ì •
model.model.model[0].conv = nn.Conv2d(9, 64, kernel_size=3, stride=2, padding=1)

# ë°ì´í„° ë¡œë”
def prepare_input(thermal, nvg, rgb_enhanced):
    # ê°ê° [B, C, H, W]
    return torch.cat([thermal, nvg, rgb_enhanced], dim=1)  # [B, 9, H, W]
```

---

### ë°©ì•ˆ 2: Late Fusion (í›„ê¸° ìœµí•©)
```
[ì—´ìƒ] â”€â”€â”€â”€â”€> Backbone A â”€â”
[ì•¼ê°„íˆ¬ì‹œ] â”€> Backbone B â”€â”¼â”€> Fusion Module â”€> Detection Head â”€> Output
[ê°€ì‹œê´‘] â”€â”€â”€> Backbone C â”€â”˜
```

**êµ¬í˜„**:
- ê° ëª¨ë‹¬ë¦¬í‹°ë§ˆë‹¤ ë…ë¦½ì ì¸ ë°±ë³¸ ë„¤íŠ¸ì›Œí¬
- ê³ ìˆ˜ì¤€(high-level) íŠ¹ì§• ë§µì„ ìœµí•©
- Fusion Module: Concat + Conv, Attention, Weighted Sum ë“±

**ì¥ì **:
- ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ì‚¬ì „í•™ìŠµ ëª¨ë¸ í™œìš© ê°€ëŠ¥ (ì „ì´í•™ìŠµ)
- í•œ ëª¨ë‹¬ë¦¬í‹° í’ˆì§ˆ ì €í•˜ ì‹œ ë‹¤ë¥¸ ëª¨ë‹¬ë¦¬í‹°ë¡œ ë³´ì™„ ê°€ëŠ¥
- ëª¨ë‹¬ë¦¬í‹°ë³„ ë…ë¦½ì  íŠ¹ì§• ì¶”ì¶œ

**ë‹¨ì **:
- íŒŒë¼ë¯¸í„° ìˆ˜ 3ë°° ì¦ê°€ (ë©”ëª¨ë¦¬/ê³„ì‚°ëŸ‰ ì¦ê°€)
- ì¶”ë¡  ì†ë„ ëŠë¦¼
- êµ¬í˜„ ë³µì¡ë„ ë†’ìŒ

**ì½”ë“œ ì˜ˆì‹œ**:
```python
class LateMultimodalYOLO(nn.Module):
    def __init__(self):
        super().__init__()
        self.thermal_backbone = YOLO('yolo11x.pt').model
        self.nvg_backbone = YOLO('yolo11x.pt').model
        self.rgb_backbone = YOLO('yolo11x.pt').model
        
        # Fusion module
        self.fusion = nn.Sequential(
            nn.Conv2d(256*3, 256, 1),  # Feature map concat
            nn.BatchNorm2d(256),
            nn.ReLU()
        )
        
        self.detection_head = DetectionHead()
    
    def forward(self, thermal, nvg, rgb):
        feat_t = self.thermal_backbone.extract_features(thermal)
        feat_n = self.nvg_backbone.extract_features(nvg)
        feat_r = self.rgb_backbone.extract_features(rgb)
        
        fused = self.fusion(torch.cat([feat_t, feat_n, feat_r], dim=1))
        return self.detection_head(fused)
```

---

### ë°©ì•ˆ 3: Mid Fusion (ì¤‘ê°„ ìœµí•©)
```
[ì—´ìƒ] â”€â”€â”€â”€â”€> Backbone Layers 1-3 â”€â”
[ì•¼ê°„íˆ¬ì‹œ] â”€> Backbone Layers 1-3 â”€â”¼â”€> Fusion â”€> Shared Layers 4-N â”€> Head
[ê°€ì‹œê´‘] â”€â”€â”€> Backbone Layers 1-3 â”€â”˜
```

**êµ¬í˜„**:
- ì´ˆê¸° ë ˆì´ì–´ëŠ” ëª¨ë‹¬ë¦¬í‹°ë³„ ë…ë¦½ (ì €ìˆ˜ì¤€ íŠ¹ì§•)
- ì¤‘ê°„ë¶€í„° ìœµí•© í›„ ê³µìœ  ë ˆì´ì–´ (ê³ ìˆ˜ì¤€ íŠ¹ì§•)

**ì¥ì **:
- Earlyì™€ Lateì˜ ì¥ì  ê²°í•©
- íŒŒë¼ë¯¸í„° íš¨ìœ¨ì  (Lateë³´ë‹¤ ì ìŒ)
- ì ì ˆí•œ ê· í˜•

**ë‹¨ì **:
- ìœµí•© ì‹œì  ê²°ì •ì´ í•˜ì´í¼íŒŒë¼ë¯¸í„° (ì‹¤í—˜ í•„ìš”)
- êµ¬í˜„ ë³µì¡ë„ ì¤‘ê°„

---

### ë°©ì•ˆ 4: Attention-based Fusion (ì¶”ì²œ â­)
```
[ì—´ìƒ] â”€â”€â”€â”€â”€> Backbone â”€â”
[ì•¼ê°„íˆ¬ì‹œ] â”€> Backbone â”€â”¼â”€> Cross-Attention â”€> Detection Head
[ê°€ì‹œê´‘] â”€â”€â”€> Backbone â”€â”˜     (ë™ì  ê°€ì¤‘ì¹˜)
```

**êµ¬í˜„**:
- ê° ëª¨ë‹¬ë¦¬í‹°ë³„ íŠ¹ì§• ì¶”ì¶œ
- Cross-Attentionìœ¼ë¡œ ì¤‘ìš”í•œ ëª¨ë‹¬ë¦¬í‹° ë™ì  ì„ íƒ
- ìƒí™©ì— ë”°ë¼ ê°€ì¤‘ì¹˜ ìë™ ì¡°ì ˆ (ì˜ˆ: ì—´ìƒ ì‹ ë¢°ë„â†‘ â†’ ì—´ìƒ ê°€ì¤‘ì¹˜â†‘)

**ì¥ì **:
- ìµœê³  ì„±ëŠ¥ (SOTA ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ë“¤ì´ ì‚¬ìš©)
- ëª¨ë‹¬ë¦¬í‹° ê°„ ìƒí˜¸ì‘ìš© í•™ìŠµ
- ì ì‘ì  ìœµí•© (ìƒí™©ë³„ ìµœì  ì¡°í•©)

**ë‹¨ì **:
- êµ¬í˜„ ë³µì¡ë„ ê°€ì¥ ë†’ìŒ
- Transformer ë¸”ë¡ í•„ìš” (ë©”ëª¨ë¦¬ ì¶”ê°€)

**ì½”ë“œ ì˜ˆì‹œ (ê°„ì†Œí™”)**:
```python
class AttentionFusion(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.cross_attn = nn.MultiheadAttention(dim, num_heads=8)
        self.norm = nn.LayerNorm(dim)
    
    def forward(self, feat_t, feat_n, feat_r):
        # [B, C, H, W] -> [HW, B, C]
        feats = torch.stack([feat_t, feat_n, feat_r], dim=0)  # [3, B, C, H, W]
        
        # Cross-attention
        attended, weights = self.cross_attn(feats, feats, feats)
        fused = self.norm(attended.mean(dim=0))  # [B, C, H, W]
        return fused
```

---

## 2. í›ˆë ¨ ì „ëµ

### ì „ëµ A: End-to-End ì§ì ‘ í•™ìŠµ
```
ì•¼ê°„ 3-way ë°ì´í„°ì…‹ â†’ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ í›ˆë ¨ (ì²˜ìŒë¶€í„°)
```

**ë°©ë²•**:
- ìˆ˜ì§‘í•œ ì•¼ê°„ 3-way ë°ì´í„°ì…‹ìœ¼ë¡œ ë°”ë¡œ í›ˆë ¨
- YOLO êµ¬ì¡° ìˆ˜ì • â†’ ëœë¤ ì´ˆê¸°í™” ë˜ëŠ” COCO ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ì¼ë¶€ í™œìš©

**ì¥ì **:
- ë‹¨ìˆœ ëª…ë£Œ
- ì‹¤ì œ ì ìš© í™˜ê²½ê³¼ ì§ì ‘ ë§¤ì¹­

**ë‹¨ì **:
- ë°ì´í„° ë¶€ì¡± ì‹œ í•™ìŠµ ì–´ë ¤ì›€
- ìˆ˜ë ´ ëŠë¦¼

---

### ì „ëµ B: ë‹¨ì¼ ëª¨ë‹¬ ì‚¬ì „í•™ìŠµ â†’ ë©€í‹°ëª¨ë‹¬ Fine-tuning (ì¶”ì²œ â­)
```
1ë‹¨ê³„: ì—´ìƒë§Œìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ (Plan C)
2ë‹¨ê³„: 3-way ì…ë ¥ìœ¼ë¡œ í™•ì¥ ë° Fine-tuning
```

**ë°©ë²•**:
1. **1ë‹¨ê³„**: ì£¼ê°„ ì—´ìƒ ë°ì´í„°ì…‹ìœ¼ë¡œ ì—´ìƒ YOLO ëª¨ë¸ ë¨¼ì € í•™ìŠµ
   ```python
   model_thermal = YOLO('yolo11x.pt')
   model_thermal.train(data='thermal.yaml', epochs=100)
   ```

2. **2ë‹¨ê³„**: í•™ìŠµëœ ì—´ìƒ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ ì´ˆê¸°í™”
   ```python
   # ì—´ìƒ ë°±ë³¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
   multimodal_model.thermal_branch.load_state_dict(model_thermal.state_dict())
   # ì•¼ê°„íˆ¬ì‹œ/ê°€ì‹œê´‘ ë¸Œëœì¹˜ë„ ë™ì¼ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™” (ì „ì´í•™ìŠµ)
   multimodal_model.nvg_branch.load_state_dict(model_thermal.state_dict())
   multimodal_model.rgb_branch.load_state_dict(model_thermal.state_dict())
   
   # Fine-tuning
   multimodal_model.train(data='multimodal.yaml', epochs=50, lr=0.0001)
   ```

**ì¥ì **:
- ì—´ìƒ ëª¨ë¸ì´ ì´ë¯¸ Person íƒì§€ ëŠ¥ë ¥ í™•ë³´
- ë©€í‹°ëª¨ë‹¬ì€ ì¶”ê°€ ì •ë³´ í™œìš©ë²•ë§Œ í•™ìŠµí•˜ë©´ ë¨
- ìˆ˜ë ´ ë¹ ë¦„, ì„±ëŠ¥ ì•ˆì •ì 

**ë‹¨ì **:
- 2ë‹¨ê³„ í›ˆë ¨ í•„ìš” (ì‹œê°„ ì†Œìš”)

---

### ì „ëµ C: ì ì§„ì  ëª¨ë‹¬ë¦¬í‹° ì¶”ê°€ (Progressive Training)
```
Step 1: ì—´ìƒë§Œ (Plan C)
Step 2: ì—´ìƒ + ì•¼ê°„íˆ¬ì‹œ (Plan B)
Step 3: ì—´ìƒ + ì•¼ê°„íˆ¬ì‹œ + ê°€ì‹œê´‘ (Plan A)
```

**ë°©ë²•**:
- ë‹¨ì¼ â†’ 2-way â†’ 3-way ìˆœì„œë¡œ ì ì§„ì  í™•ì¥
- ê° ë‹¨ê³„ë§ˆë‹¤ ìƒˆ ëª¨ë‹¬ë¦¬í‹° ë¸Œëœì¹˜ ì¶”ê°€ ë° Fine-tuning

**ì¥ì **:
- ê° ëª¨ë‹¬ë¦¬í‹°ì˜ ê¸°ì—¬ë„ë¥¼ ë‹¨ê³„ë³„ë¡œ í™•ì¸ ê°€ëŠ¥
- ì•ˆì •ì  í•™ìŠµ ê²½ë¡œ
- ë¬¸ì œ ë°œìƒ ì‹œ ì´ì „ ë‹¨ê³„ë¡œ ë¡¤ë°± ê°€ëŠ¥

**ë‹¨ì **:
- í›ˆë ¨ ì‹œê°„ ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼

---

### ì „ëµ D: Knowledge Distillation (ì§€ì‹ ì¦ë¥˜)
```
Teacher: ê°œë³„ ë‹¨ì¼ ëª¨ë‹¬ ëª¨ë¸ 3ê°œ (ê°ê° ê³ ì„±ëŠ¥)
Student: 3-way ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ (íš¨ìœ¨ì )
```

**ë°©ë²•**:
1. ì—´ìƒ, ì•¼ê°„íˆ¬ì‹œ, ê°€ì‹œê´‘ ê°ê° ë‹¨ì¼ ëª¨ë¸ í›ˆë ¨ (Teacher)
2. Student ëª¨ë¸ì´ 3ê°œ Teacherì˜ ì¶œë ¥ì„ ëª¨ë‘ ëª¨ë°©í•˜ë„ë¡ í•™ìŠµ
   ```python
   loss = detection_loss + distillation_loss
   distillation_loss = KL_div(student_output, teacher_thermal_output) +
                       KL_div(student_output, teacher_nvg_output) +
                       KL_div(student_output, teacher_rgb_output)
   ```

**ì¥ì **:
- Student ëª¨ë¸ì´ 3ê°œ ëª¨ë¸ì˜ ì§€ì‹ ëª¨ë‘ í¡ìˆ˜
- ë‹¨ì¼ ëª¨ë¸ë¡œ 3ê°œ ëª¨ë¸ ì„±ëŠ¥ ê·¼ì ‘ ê°€ëŠ¥

**ë‹¨ì **:
- Teacher ëª¨ë¸ 3ê°œ ë¨¼ì € í•™ìŠµ í•„ìš”
- êµ¬í˜„ ë³µì¡

---

## 3. ë°ì´í„° ì¦ê°• ì „ëµ

### 3-1. ëª¨ë‹¬ë¦¬í‹°ë³„ ì¦ê°•
```python
# ì—´ìƒ: ì˜¨ë„ ê¸°ë°˜ì´ë¯€ë¡œ ìƒ‰ìƒ ì™œê³¡ X, ë°ê¸°/ëŒ€ë¹„ë§Œ
thermal_aug = A.Compose([
    A.RandomBrightnessContrast(p=0.5),
    A.GaussianBlur(p=0.3),
    A.RandomRotate90(p=0.5)
])

# ì•¼ê°„íˆ¬ì‹œ: ë…¹ìƒ‰ ë‹¨ìƒ‰ì´ë¯€ë¡œ ë°ê¸° ë³€í™”
nvg_aug = A.Compose([
    A.RandomGamma(p=0.5),
    A.GaussNoise(p=0.3)
])

# Enhanced ê°€ì‹œê´‘: RGBì´ë¯€ë¡œ ì¼ë°˜ ì¦ê°• ê°€ëŠ¥
rgb_aug = A.Compose([
    A.HueSaturationValue(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.ChannelShuffle(p=0.2)
])
```

### 3-2. ë™ê¸°í™”ëœ ê³µê°„ ì¦ê°•
```python
# 3ê°œ ëª¨ë‹¬ë¦¬í‹°ì— ë™ì¼í•œ ê³µê°„ ë³€í™˜ ì ìš©
spatial_aug = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(p=0.5),
    A.RandomCrop(640, 640)
], additional_targets={'nvg': 'image', 'rgb': 'image'})

transformed = spatial_aug(
    image=thermal,  # ê¸°ë³¸
    nvg=nvg,        # ì¶”ê°€ íƒ€ê²Ÿ 1
    rgb=rgb         # ì¶”ê°€ íƒ€ê²Ÿ 2
)
```

---

## 4. Loss Function ì„¤ê³„

### 4-1. ê¸°ë³¸ Detection Loss
```python
total_loss = Î»1 Ã— box_loss + Î»2 Ã— cls_loss + Î»3 Ã— obj_loss

# YOLO ê¸°ë³¸ Loss
- box_loss: CIoU Loss (bbox ì •í™•ë„)
- cls_loss: BCE Loss (í´ë˜ìŠ¤ ë¶„ë¥˜, Person vs Background)
- obj_loss: BCE Loss (ê°ì²´ ì¡´ì¬ ì—¬ë¶€)
```

### 4-2. ë©€í‹°ëª¨ë‹¬ ì¶”ê°€ Loss (ì„ íƒì )

**Consistency Loss** (ëª¨ë‹¬ë¦¬í‹° ê°„ ì¼ê´€ì„±):
```python
# ê° ëª¨ë‹¬ë¦¬í‹°ë³„ë¡œ ì˜ˆì¸¡í•œ bboxê°€ ìœ ì‚¬í•´ì•¼ í•¨
consistency_loss = MSE(bbox_thermal, bbox_nvg) + 
                   MSE(bbox_nvg, bbox_rgb) +
                   MSE(bbox_rgb, bbox_thermal)

total_loss += Î»4 Ã— consistency_loss
```

**Modality Attention Loss** (ì¤‘ìš” ëª¨ë‹¬ë¦¬í‹° í•™ìŠµ):
```python
# ê° ìƒí™©ì—ì„œ ì–´ë–¤ ëª¨ë‹¬ë¦¬í‹°ê°€ ì¤‘ìš”í•œì§€ í•™ìŠµ
# Attention weightsì˜ ì—”íŠ¸ë¡œí”¼ ìµœì†Œí™” (ëª…í™•í•œ ì„ íƒ)
entropy_loss = -sum(attention_weights * log(attention_weights))

total_loss += Î»5 Ã— entropy_loss
```

---

## 5. í‰ê°€ ë° ì‹¤í—˜ ê³„íš

### Phase 1: Baseline êµ¬ì¶•
```
1. Plan C (ì—´ìƒë§Œ) í•™ìŠµ â†’ mAP ì¸¡ì • (Baseline)
2. Plan B (ì—´ìƒ + ì•¼ê°„íˆ¬ì‹œ) í•™ìŠµ â†’ mAP ë¹„êµ
3. Plan A (3-way) í•™ìŠµ â†’ mAP ë¹„êµ
```

### Phase 2: ìœµí•© ë°©ë²• ë¹„êµ
```
ë™ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ:
- Early Fusion â†’ mAP
- Late Fusion â†’ mAP
- Mid Fusion â†’ mAP
- Attention Fusion â†’ mAP
```

### Phase 3: ìµœì í™”
```
ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ í›„:
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- ë°ì´í„° ì¦ê°• ìµœì í™”
- Ablation Study (ê° ëª¨ë‹¬ë¦¬í‹° ì œê±° ì‹¤í—˜)
```

---

## 6. ì¶”ì²œ ë°©ì•ˆ ìš”ì•½

### ğŸ† ìµœì¢… ì¶”ì²œ ì¡°í•©

**ì•„í‚¤í…ì²˜**: **Attention-based Fusion (ë°©ì•ˆ 4)**
- ìµœê³  ì„±ëŠ¥ ê¸°ëŒ€
- ì ì‘ì  ìœµí•©

**í›ˆë ¨ ì „ëµ**: **ë‹¨ì¼ ëª¨ë‹¬ ì‚¬ì „í•™ìŠµ â†’ Fine-tuning (ì „ëµ B)**
- ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ìˆ˜ë ´
- ì—´ìƒ ëª¨ë¸ ë¨¼ì € í™•ë³´

**êµ¬í˜„ ìˆœì„œ**:
```
1. ì—´ìƒ ë‹¨ì¼ ëª¨ë¸ í•™ìŠµ (Plan C) âœ… Baseline í™•ë³´
2. 2-way ëª¨ë¸ (ì—´ìƒ + ì•¼ê°„íˆ¬ì‹œ) ì‹¤í—˜
3. 3-way ëª¨ë¸ (+ Enhanced ê°€ì‹œê´‘) ìµœì¢…
4. Attention Fusion ì ìš©í•˜ì—¬ ìµœì í™”
```

---

## 7. ì‹¤ì œ ì½”ë“œ ë¼ˆëŒ€ (PyTorch + Ultralytics YOLO)

```python
from ultralytics import YOLO
import torch
import torch.nn as nn

class MultimodalYOLO(nn.Module):
    def __init__(self, backbone='yolo11x.pt'):
        super().__init__()
        
        # ê° ëª¨ë‹¬ë¦¬í‹° ë°±ë³¸ (ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ í™œìš©)
        base_model = YOLO(backbone).model
        self.thermal_backbone = base_model.clone()
        self.nvg_backbone = base_model.clone()
        self.rgb_backbone = base_model.clone()
        
        # Attention Fusion
        self.fusion = CrossModalAttention(dim=512)
        
        # Detection Head (YOLO head ì¬ì‚¬ìš©)
        self.detection_head = base_model.head
    
    def forward(self, thermal, nvg, rgb):
        # Feature extraction
        feat_t = self.thermal_backbone.backbone(thermal)
        feat_n = self.nvg_backbone.backbone(nvg)
        feat_r = self.rgb_backbone.backbone(rgb)
        
        # Fusion
        fused_feat = self.fusion(feat_t, feat_n, feat_r)
        
        # Detection
        output = self.detection_head(fused_feat)
        return output

# Training
model = MultimodalYOLO()
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)

for epoch in range(100):
    for batch in dataloader:
        thermal, nvg, rgb, labels = batch
        
        output = model(thermal, nvg, rgb)
        loss = compute_yolo_loss(output, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

---

ì´ ì¤‘ì—ì„œ ì–´ë–¤ ë°©ì•ˆì´ ê°€ì¥ ë§ˆìŒì— ë“œì‹œë‚˜ìš”? ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì ‘ê·¼ë²•ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?